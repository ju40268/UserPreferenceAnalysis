    1  ls
    2  wget https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda-2.3.0-Linux-x86_64.sh
    3  ls
    4  bash Anaconda-2.3.0-Linux-x86_64.sh 
    5  conda
    6  where conda
    7  echo 'export PATH="~/anaconda/bin:$PATH"' >> ~/.bashrc 
    8  source .bashrc
    9  conda --list
   10  conda -list
   11  conda h
   12  conda -h
   13  conda update conda
   14  conda install -c conda-forge keras=2.0.2
   15  python
   16  pip install --upgrade -I setuptools
   17  pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl
   18  mkdir -p ~/.keras
   19  echo '{"epsilon":1e-07,"floatx":"float32","backend":"tensorflow"}' > ~/.keras/keras.json
   20  python
   21  sudo aot update
   22  sudo apt update
   23  sudp apt upgrade
   24  sudo apt upgrade
   25  sudo apt install -y python-dev python-pip python-nose gcc g++ git gfortran vim
   26  python
   27  sudo pip install tensorflow --upgrade
   28  pip install tensorflow --upgrade
   29  python
   30  sudo apt install -y libopenblas-dev liblapack-dev libatlas-base-dev
   31  history
   32  gedit resnet152.py
   33  vim resnet152.py
   34  sudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make
   35  add-apt-repository ppa:ubuntu-desktop/ubuntu-make
   36  sudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make
   37  sudo apt-get update
   38  sudo apt-get install ubuntu-make
   39  umake ide pycharm
   40  ls
   41  pycharn
   42  pycharm
   43  charm
   44  sudo apt-get install pycharm-community
   45  apt-get install pycharm-community
   46  ls
   47  python resnet152.py 
   48  git clone https://github.com/flyyufelix/cnn_finetune.git
   49  ls
   50  rm resnet152.py 
   51  cd cnn_finetune/
   52  ls
   53  python resnet_152.py 
   54  spyder
   55  gedit
   56  sudo apt-get install gedit
   57  gedit resnet_152.py 
   58  sudo apt-get remove gedit
   59  java -version
   60  python
   61  ls
   62  la
   63  ls
   64  ls -al
   65  conda install -c https://conda.binstar.org/menpo opencv
   66  python
   67  python 
   68  aws help
   69  exit
   70  ls
   71  pyspark
   72  conda
   73  ls
   74  conda -version
   75  conda -V
   76  python
   77  ls
   78  cd
   79  python
   80  ls
   81  java -version
   82  sudo apt-get update
   83  sudo apt-get install default-jre
   84  sudo apt-get install default-jdk
   85  sudo add-apt-repository ppa:webupd8team/java
   86  sudo apt-get update
   87  sudo apt-get instakk oracle-java8-installer
   88  sudo apt-get install oracle-java8-installer
   89  java -version
   90  sudo apt-get install oracle-java8-set-default
   91  vim .bashrc
   92  export JAVA_HOME=/usr/lib/jvm/java-8-oracle
   93  export JRE_HOME=/usr/lib/jvm/java-8-oracle/jre
   94  source .bashrc
   95  echo $JAVA_HOME
   96  which python
   97  ls
   98  ls -ak
   99  vim .viminfo 
  100  cd /usr
  101  ls
  102  cd share/
  103  ls
  104  cd vim
  105  ls
  106  cd vim74
  107  ls
  108  vim colors/
  109  cd colors/
  110  ls
  111  cd ..
  112  ls
  113  cd 
  114  ls
  115  ls -al
  116  cd .vim/
  117  ls
  118  cd
  119  vim .viminfo 
  120  vim .bashrc
  121  source .bashr
  122  source .bashrc
  123  ls
  124  cd cnn_finetune/
  125  ls
  126  cd ..
  127  ls
  128  vim .bashrc
  129  ls
  130  vim .bashrc
  131  source .bashrc
  132  ls
  133  clear
  134  which python
  135  jupyter notebook --generate-config
  136  source bin/activate
  137  ls
  138  cd /usr/bin
  139  ls
  140  conda --version
  141  pip install jupyter
  142  jupyter notebook --generate-config
  143  mkdir certs
  144  cd
  145  mkdir certs
  146  cd certs/
  147  ls
  148  cd
  149  ls
  150  git clone https://github.com/may811204/song_user_preference.git
  151  ls
  152  cd song_user_preference/
  153  ls
  154  mv ufo_server_key.pem ../
  155  ls
  156  cd
  157  ls
  158  pwd
  159  mv ufo_server_key.pem certs/
  160  ls
  161  sudo openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout ufo_server_key.pem -out ufo_server_key.pem
  162  ls
  163  cd ~/.jupyter/
  164  vim jupyter_notebook_config.py 
  165  jupyter notebook
  166  exit
  167  ipython
  168  ls
  169  sudo apt-get update
  170  sudo apt-get install scala
  171  scala -version
  172  conda install pip
  173  which pip
  174  pip install py4j
  175  wget http://archive.apache.org/dist/spark/spark-2.0.0/spark-2.1.1-bin-hadoop2.7.tgz
  176  wget http://archive.apache.org/dist/spark/spark-2.1.1/spark-2.1.1-bin-hadoop2.7.tgz
  177  ls
  178  sudo tar -zxvf spark-2.1.1-bin-hadoop2.7.tgz 
  179  ls
  180  pwd
  181  export SPARK_HOME='/home/ubuntu/spark-2.1.1-bin-hadoop2.7'
  182  export PATH=$SPARK_HOME:$PATH
  183  export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH
  184  source .bashrc
  185  ls
  186  pyspark
  187  echo $SPARK_HOME
  188  echo $PATH
  189  echo $PYTHONPATH
  190  jupyter notebook
  191  python
  192  cd ..
  193  cd
  194  ls
  195  cd song_user_preference/
  196  ls
  197  python load_obj.py 
  198  pip install boto3
  199  python load_obj.py 
  200  pip install boto
  201  pip install boto3
  202  pip upgrade
  203  python
  204  exit
  205  ls
  206  cd song_user_preference/
  207  ls
  208  python load_obj.py 
  209  vim load_obj.py 
  210  rm load_obj.py 
  211  vim load_obj.py
  212  python load_obj.py 
  213  pip install findspark
  214  python load_obj.py 
  215  ls
  216  echo $SPARK_HOME
  217  export SPARK_HOME='/home/ubuntu/spark-2.1.1-bin-hadoop2.7'
  218  export PATH=$SPARK_HOME:$PATH
  219  export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH
  220  echo $SPARK_HOME
  221  source .bashrc
  222  cd
  223  source .bashrc
  224  echo $SPARK_HOME
  225  cd song_user_preference/
  226  python load_obj.py 
  227  aws --version
  228  ls
  229  aws
  230  pip install awscli
  231  aws --version
  232  pip -version
  233  pip --version
  234  export PATH=~/.local/bin:$PATH
  235  cd
  236  source ~/.bash_profile
  237  source .bashrc
  238  pip --version
  239  pip install awscli --upgrade --user
  240  aws
  241  aws help
  242  aws configure
  243  aws configure list
  244  cd song_user_preference/
  245  python load_obj.py 
  246  ls
  247  vim load_obj.py 
  248  python load_obj.py 
  249  cd
  250  la
  251  ls
  252  cd song_user_preference/
  253  ls
  254  python temp.py 
  255  vim temp.py
  256  vim test.py
  257  python test.py
  258  vim test.py
  259  python test.py
  260  vim test.py
  261  python test.py
  262  vim test.py
  263  python test.py
  264  python
  265  python test.py
  266  ls
  267  cd /etc/dhcp/dhclient-exit-hooks.d/
  268  ls
  269  setup.sh
  270  vim setup.sh
  271  sudo vim setup.sh
  272  bash setup.sh
  273  sudo bash setup.sh
  274  cd /etc/hosts
  275  cd /etc/host
  276  cd /etc
  277  ks
  278  ls
  279  vim hostname
  280  vim hosts
  281  cd hosts
  282  ls
  283  vim hosts
  284  cd
  285  ls
  286  cd song_user_preference/
  287  python load_obj.py 
  288  vim load_obj.py 
  289  python load_obj.py 
  290  vim load_obj.py 
  291  python load_obj.py 
  292  aws s3 ls s3://aws21-squeezebox-analysis-output
  293  jupyter notebook
  294  ls
  295  history > install_pyspark.log
